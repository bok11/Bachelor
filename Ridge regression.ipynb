{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre processing function\n",
    "def zscale(x, mean, std):\n",
    "    result = np.subtract(x, mean)\n",
    "    \n",
    "    result = np.divide(result, std, out=np.zeros_like(result), where=std!=0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def norma(x, min, max): \n",
    "    result = np.subtract(x, min)\n",
    "    \n",
    "    result = np.divide(result, np.subtract(max, min), out=np.zeros_like(result), where=np.subtract(max, min)!=0)\n",
    "    return result\n",
    "\n",
    "\n",
    "# model \n",
    "# http://web.as.uky.edu/statistics/users/pbreheny/764-f11/notes/9-1.pdf\n",
    "# slide 3\n",
    "def ridge_regression(X, y, lam):\n",
    "    xtranspose = np.transpose(X)\n",
    "    xtransx = np.dot(xtranspose, X)\n",
    "    lamidentity = np.identity(xtransx.shape[0]) * lam\n",
    "    matinv = np.linalg.inv(lamidentity + xtransx)\n",
    "    xtransy = np.dot(xtranspose, y)\n",
    "    # return betas\n",
    "    return np.dot(matinv, xtransy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MCVDDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "        \"\"\"\n",
    "        self.mcvd_data = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.mcvd_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        data = self.mcvd_data.iloc[idx][6:].values.astype('float32')\n",
    "        target = (self.mcvd_data.iloc[idx][2])\n",
    "        sample = {'data': data, 'target': target}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_valid_train_split(df,split=0.25,randomseed=None, silent=False,minimum =2):\n",
    "    prodids = df['prodid'].unique()\n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "\n",
    "    for prodid in prodids:\n",
    "        if (df[df['prodid'] == prodid].shape[0] <minimum):\n",
    "            if (not silent):\n",
    "                print(\"Skipped prodid {} with {} entries\".format(prodid,df[df['prodid'] == prodid].shape[0]))\n",
    "        else:\n",
    "            #References\n",
    "            index = df[(df['prodid'] == prodid) & (df['targetval']-df['val'] == 0)].index\n",
    "            train,test = train_test_split(index,test_size=split ,random_state=randomseed)\n",
    "            [train_idx.append(value) for value in train]\n",
    "            [test_idx.append(value) for value in test]\n",
    "\n",
    "            #Targets\n",
    "            index = df[(df['prodid'] == prodid) & (df['targetval']-df['val'] != 0)].index\n",
    "            train,test = train_test_split(index,test_size=split ,random_state=randomseed)\n",
    "            [train_idx.append(value) for value in train]\n",
    "            [test_idx.append(value) for value in test]\n",
    "            \n",
    "    return train_idx, test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = MCVDDataset(csv_file='dataset-goldenref.csv')\n",
    "dataset.mcvd_data = dataset.mcvd_data.drop('Unnamed: 0',axis=1)\n",
    "dataset.mcvd_data['starttime'] = pd.to_datetime(dataset.mcvd_data['starttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomseed=23\n",
    "k_fold=5\n",
    "split = 0.20\n",
    "train_idx, test_idx = get_valid_train_split(dataset.mcvd_data,split=split,randomseed=randomseed,silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.empty([0,341])\n",
    "Y_train = np.empty([0,1])\n",
    "\n",
    "for idx in train_idx:\n",
    "    X_train = np.append(X_train,dataset.__getitem__(idx)['data'].reshape(1,341),axis=0)\n",
    "    Y_train = np.append(Y_train,dataset.__getitem__(idx)['target'].reshape(1,1),axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "X_test = np.empty([0,341])\n",
    "Y_test = np.empty([0,1])\n",
    "M_test = np.empty([0,1])\n",
    "for idx in test_idx:\n",
    "    X_test = np.append(X_test,dataset.__getitem__(idx)['data'].reshape(1,341),axis=0)\n",
    "    Y_test = np.append(Y_test,dataset.__getitem__(idx)['target'].reshape(1,1),axis=0)\n",
    "    M_test =  np.append(M_test,dataset.mcvd_data.iloc[idx,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = dataset.mcvd_data.loc[train_idx].reset_index()\n",
    "idxcv1 = df.loc[df['adjustment'] !=0].index.values\n",
    "\n",
    "idxcv2 = df.loc[df['adjustment'] ==0].index.values\n",
    "\n",
    "cv1 = np.array_split(idxcv1, k_fold)\n",
    "cv2 = np.array_split(idxcv2, k_fold)\n",
    "\n",
    "\n",
    "folds = [np.concatenate((cv1[i], cv2[i])) for i in range(k_fold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "best MSE: 0.117638874662\n",
      "best lambda: 27843.4060677 \n",
      "\n",
      "fold: 2\n",
      "best MSE: 0.0237854018976\n",
      "best lambda: 100000.0 \n",
      "\n",
      "fold: 3\n",
      "best MSE: 0.0118319582896\n",
      "best lambda: 100000.0 \n",
      "\n",
      "fold: 4\n",
      "best MSE: 0.0216310183759\n",
      "best lambda: 100000.0 \n",
      "\n",
      "fold: 5\n",
      "best MSE: 0.0216217272771\n",
      "best lambda: 10580.6477499 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CV\n",
    "idx_cv = np.random.choice(np.arange(X_train.shape[0]), replace=False, size=int(X_train.shape[0] * split))\n",
    "\n",
    "\n",
    "# hyperparamters\n",
    "n_steps = 2000\n",
    "my_lambda = np.logspace(start=-5, stop=5, num=n_steps)\n",
    "dev_loss = np.empty((k_fold, n_steps))\n",
    "\n",
    "\n",
    "for i, idx_dev_cv in enumerate(folds):\n",
    "    print(\"fold: \" + str(i+1))\n",
    "\n",
    "    \n",
    "    idx_train_cv = np.array([i for i in np.arange(X_train.shape[0]) if not i in idx_dev_cv])\n",
    "    # create train and dev data\n",
    "    \n",
    "    X_train_cv = X_train[idx_train_cv,]\n",
    "    Y_train_cv = Y_train[idx_train_cv]\n",
    "    \n",
    "    X_dev_cv = X_train[idx_dev_cv,]\n",
    "    Y_dev_cv = Y_train[idx_dev_cv]\n",
    "\n",
    "    # find properties...\n",
    "    mean = np.mean(X_train_cv, axis=0)\n",
    "    std = np.std(X_train_cv, axis=0)\n",
    "    train_max = np.max(Y_train_cv)\n",
    "    train_min = np.min(Y_train_cv)\n",
    "    # min = np.min(X_train_cv, axis=0)\n",
    "    # max = np.max(X_train_cv, axis=0)\n",
    "    \n",
    "    \n",
    "    # pre-process\n",
    "    #X_train_cv = zscale(X_train_cv, mean, std)\n",
    "    #X_dev_cv = zscale(X_dev_cv, mean, std)\n",
    "    #X_train_cv = norma(X_train_cv, mean, std)\n",
    "    #X_dev_cv = norma(X_dev_cv, mean, std)\n",
    "    \n",
    "    \n",
    "    for j, lam in enumerate(my_lambda):\n",
    "        # fit \n",
    "        # clf = Ridge(alpha=lam, fit_intercept=False, normalize=True)\n",
    "        # clf.fit(X_train_cv, Y_train_cv)\n",
    "        betas = ridge_regression(X_train_cv, Y_train_cv, lam)\n",
    "        \n",
    "        # predict and get loss\n",
    "        # Y_dev_cv_hat = clf.predict(X_dev_cv)\n",
    "        Y_dev_cv_hat = np.dot(X_dev_cv, betas)\n",
    "        dev_loss[i,j] = np.sum(np.power(Y_dev_cv - Y_dev_cv_hat,2))\n",
    "        \n",
    "        \n",
    "    print('best MSE:', np.min(dev_loss[i,]))\n",
    "    print('best lambda:', my_lambda[np.argmin(dev_loss[i,])], '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the opt. lambda is: 67684.8107635\n",
      "best MSE: 0.000454439687166\n"
     ]
    }
   ],
   "source": [
    "# # One std. error rule\n",
    "# std_means = np.std(dev_loss, axis=0) / np.sqrt(k_fold)\n",
    "# mse_means = np.mean(dev_loss, axis=0)\n",
    "# best_idx_std_means = np.argmin(std_means)\n",
    "# best_idx_std_means = np.max(np.where(std_means[best_idx_std_means] + std_means[best_idx_std_means] > std_means)[0])\n",
    "# my_lambda_opt = my_lambda[best_idx_std_means]\n",
    "\n",
    "# # GLOBAL\n",
    "# my_lambda_opt = my_lambda[np.argmin(np.mean(dev_loss, axis=0))]\n",
    "\n",
    "# LOCAL\n",
    "my_lambda_opt = np.mean([my_lambda[np.argmin(dev_loss[i,])] for i in range(dev_loss.shape[0])])\n",
    "print('the opt. lambda is: ' + str(my_lambda_opt))\n",
    "\n",
    "# find properties...\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "train_max = np.max(Y_train)\n",
    "train_min = np.min(Y_train)\n",
    "# min = np.min(X_train_cv, axis=0)\n",
    "# max = np.max(X_train_cv, axis=0)\n",
    "\n",
    "# pre-process\n",
    "#X_train = zscale(X_train, mean, std)\n",
    "#X_test = zscale(X_test, mean, std)\n",
    "\n",
    "#Y_train = norma(Y_train, mean, std)\n",
    "#Y_test = norma(Y_test, mean, std)\n",
    "\n",
    "#clf = Ridge(alpha=my_lambda_opt)\n",
    "#clf.fit(X_train, Y_train)\n",
    "betas_opt = ridge_regression(X_train, Y_train, lam)\n",
    "Y_test_hat = np.dot(X_test, betas_opt)\n",
    "#Y_test_hat = clf.predict(X_test)\n",
    "\n",
    "print('best MSE:', np.mean(np.power(Y_test - Y_test_hat,2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_train: 0.0005898952477351343\n",
      "MSE_valid: 0.000454439687165606\n"
     ]
    }
   ],
   "source": [
    "print('MSE_train: {}'.format(mean_squared_error(Y_train,np.dot(X_train, betas_opt))))\n",
    "print('MSE_valid: {}'.format(mean_squared_error(Y_test,np.dot(X_test, betas_opt))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.empty([0,341])\n",
    "Y_test = np.empty([0,1])\n",
    "M_test = np.empty([0,1])\n",
    "for idx in test_idx:\n",
    "    X_test = np.append(X_test,dataset.__getitem__(idx)['data'].reshape(1,341),axis=0)\n",
    "    Y_test = np.append(Y_test,dataset.__getitem__(idx)['target'].reshape(1,1),axis=0)\n",
    "    M_test =  np.append(M_test,dataset.mcvd_data.iloc[idx,0])\n",
    "\n",
    "# pre-process\n",
    "#X_test = zscale(X_test, mean, std)\n",
    "#X_test = norma(X_test, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAEgCAYAAABy9ZCSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhIg/wCK5z2tYPryV8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1faf6ef1d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "Title = \"True value vs residual\"\n",
    "x_label =\"True value\"\n",
    "y_label = \"Residual\"\n",
    "savename = \"Ridge-raw\"\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color='black',marker='o',linestyle='none'),\n",
    "                Line2D([0], [0], color='dodgerblue',marker='o',linestyle='none'),\n",
    "                Line2D([0], [0], color='red',marker='o',linestyle='none'),\n",
    "               Line2D([0], [0], color='green',marker='o',linestyle='none')]\n",
    "\n",
    "color_map = {'m21' : 'black','m22': 'dodgerblue','m24': 'red','m25':'green'}\n",
    "preds = np.dot(X_test, betas_opt)\n",
    "\n",
    "\n",
    "for i,m in enumerate(M_test):\n",
    "    color = color_map[m]\n",
    "    plt.plot(Y_test[i],preds[i]-Y_test[i],marker='o', color=color,linestyle='none')\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.axhline(y=0.0, color='blue', linestyle=':')  \n",
    "ax = plt.gca()\n",
    "ax.legend(custom_lines, ['M21', 'M22', 'M24','M25'],bbox_to_anchor=(1.27, 1),fontsize='x-large')\n",
    "ax.set_xlabel(x_label,size=15)\n",
    "ax.set_ylabel(y_label,size=15)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "ax.set_title(Title,size=15)\n",
    "fig = ax.get_figure()\n",
    "plt.show()\n",
    "fig.savefig(\"{}.pdf\".format(savename), bbox_inches='tight')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# settings\n",
    "Title = \"True value vs residual\"\n",
    "x_label =\"True value\"\n",
    "y_label = \"Residual\"\n",
    "savename = \"Ridge-raw\"\n",
    "\n",
    "plt.plot(S['True'],S['Pred']-S['True'],marker='o', color='dodgerblue',linestyle='none')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel(x_label,size=15)\n",
    "ax.set_ylabel(y_label,size=15)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "ax.set_title(Title,size=15)\n",
    "fig = ax.get_figure()\n",
    "#fig.savefig(\"{}.pdf\".format(savename), bbox_inches='tight')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEgCAYAAABrfn40AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x204704f3b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSE_train                                          0.000361334\n",
       "MSE_valid                                          0.000212982\n",
       "Pred         [0.0173350552471, 0.000585133882966, 0.0133309...\n",
       "True         [0.0, 0.0, 0.06, 0.05, 0.0, 0.0, 0.0, -0.01, 0...\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Raw input, exclude 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "best MSE: 0.156135644841\n",
      "best lambda: 43633.4858587 \n",
      "\n",
      "fold: 2\n",
      "best MSE: 0.0244054674076\n",
      "best lambda: 100000.0 \n",
      "\n",
      "fold: 3\n",
      "best MSE: 0.0180149747595\n",
      "best lambda: 100000.0 \n",
      "\n",
      "fold: 4\n",
      "best MSE: 0.0406224775806\n",
      "best lambda: 57528.0879853 \n",
      "\n",
      "fold: 5\n",
      "best MSE: 0.0320738325323\n",
      "best lambda: 100000.0 \n",
      "\n",
      "the opt. lambda is: 80232.3147688\n",
      "best MSE: 0.000402137872537\n"
     ]
    }
   ],
   "source": [
    "dataset = MCVDDataset(csv_file='dataset.csv')\n",
    "dataset.mcvd_data = dataset.mcvd_data.drop('Unnamed: 0',axis=1)\n",
    "dataset.mcvd_data['starttime'] = pd.to_datetime(dataset.mcvd_data['starttime'])\n",
    "dataset.mcvd_data = dataset.mcvd_data[dataset.mcvd_data['adjustment'] != 0].reset_index(drop=True)\n",
    "\n",
    "randomseed=23\n",
    "k_fold=5\n",
    "split = 0.20\n",
    "train_idx, test_idx = get_valid_train_split(dataset.mcvd_data,split=split,randomseed=randomseed,silent=True)\n",
    "\n",
    "X_train = np.empty([0,344])\n",
    "Y_train = np.empty([0,1])\n",
    "for idx in train_idx:\n",
    "    X_train = np.append(X_train,dataset.__getitem__(idx)['data'].reshape(1,344),axis=0)\n",
    "    Y_train = np.append(Y_train,dataset.__getitem__(idx)['target'].reshape(1,1),axis=0)\n",
    "    \n",
    "    \n",
    "X_test = np.empty([0,344])\n",
    "Y_test = np.empty([0,1])\n",
    "for idx in test_idx:\n",
    "    X_test = np.append(X_test,dataset.__getitem__(idx)['data'].reshape(1,344),axis=0)\n",
    "    Y_test = np.append(Y_test,dataset.__getitem__(idx)['target'].reshape(1,1),axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "df = dataset.mcvd_data.loc[train_idx].reset_index()\n",
    "idxcv1 = df.loc[df['adjustment'] !=0].index.values\n",
    "\n",
    "idxcv2 = df.loc[df['adjustment'] ==0].index.values\n",
    "\n",
    "cv1 = np.array_split(idxcv1, k_fold)\n",
    "cv2 = np.array_split(idxcv2, k_fold)\n",
    "\n",
    "\n",
    "folds = [np.concatenate((cv1[i], cv2[i])) for i in range(k_fold)]\n",
    "\n",
    "# CV\n",
    "idx_cv = np.random.choice(np.arange(X_train.shape[0]), replace=False, size=int(X_train.shape[0] * split))\n",
    "\n",
    "\n",
    "# hyperparamters\n",
    "n_steps = 2000\n",
    "my_lambda = np.logspace(start=-5, stop=5, num=n_steps)\n",
    "dev_loss = np.empty((k_fold, n_steps))\n",
    "\n",
    "\n",
    "for i, idx_dev_cv in enumerate(folds):\n",
    "    print(\"fold: \" + str(i+1))\n",
    "\n",
    "    \n",
    "    idx_train_cv = np.array([i for i in np.arange(X_train.shape[0]) if not i in idx_dev_cv])\n",
    "    # create train and dev data\n",
    "    \n",
    "    X_train_cv = X_train[idx_train_cv,]\n",
    "    Y_train_cv = Y_train[idx_train_cv]\n",
    "    \n",
    "    X_dev_cv = X_train[idx_dev_cv,]\n",
    "    Y_dev_cv = Y_train[idx_dev_cv]\n",
    "\n",
    "    # find properties...\n",
    "    mean = np.mean(X_train_cv, axis=0)\n",
    "    std = np.std(X_train_cv, axis=0)\n",
    "    # min = np.min(X_train_cv, axis=0)\n",
    "    # max = np.max(X_train_cv, axis=0)\n",
    "    \n",
    "    \n",
    "    # pre-process\n",
    "    #X_train_cv = zscale(X_train_cv, mean, std)\n",
    "    #X_dev_cv = zscale(X_dev_cv, mean, std)\n",
    "    # X_train_cv = norma(X_train_cv, mean, std)\n",
    "    # X_dev_cv = norma(X_dev_cv, mean, std)\n",
    "    \n",
    "    \n",
    "    for j, lam in enumerate(my_lambda):\n",
    "        # fit \n",
    "        # clf = Ridge(alpha=lam, fit_intercept=False, normalize=True)\n",
    "        # clf.fit(X_train_cv, Y_train_cv)\n",
    "        betas = ridge_regression(X_train_cv, Y_train_cv, lam)\n",
    "        \n",
    "        # predict and get loss\n",
    "        # Y_dev_cv_hat = clf.predict(X_dev_cv)\n",
    "        Y_dev_cv_hat = np.dot(X_dev_cv, betas)\n",
    "        dev_loss[i,j] = np.sum(np.power(Y_dev_cv - Y_dev_cv_hat,2))\n",
    "        \n",
    "        \n",
    "    print('best MSE:', np.min(dev_loss[i,]))\n",
    "    print('best lambda:', my_lambda[np.argmin(dev_loss[i,])], '\\n')\n",
    "\n",
    "\n",
    "# # One std. error rule\n",
    "# std_means = np.std(dev_loss, axis=0) / np.sqrt(k_fold)\n",
    "# mse_means = np.mean(dev_loss, axis=0)\n",
    "# best_idx_std_means = np.argmin(std_means)\n",
    "# best_idx_std_means = np.max(np.where(std_means[best_idx_std_means] + std_means[best_idx_std_means] > std_means)[0])\n",
    "# my_lambda_opt = my_lambda[best_idx_std_means]\n",
    "\n",
    "# # GLOBAL\n",
    "# my_lambda_opt = my_lambda[np.argmin(np.mean(dev_loss, axis=0))]\n",
    "\n",
    "# LOCAL\n",
    "my_lambda_opt = np.mean([my_lambda[np.argmin(dev_loss[i,])] for i in range(dev_loss.shape[0])])\n",
    "print('the opt. lambda is: ' + str(my_lambda_opt))\n",
    "\n",
    "# find properties...\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "# min = np.min(X_train_cv, axis=0)\n",
    "# max = np.max(X_train_cv, axis=0)\n",
    "\n",
    "# pre-process\n",
    "#X_train = zscale(X_train, mean, std)\n",
    "#X_test = zscale(X_test, mean, std)\n",
    "# X_train = norma(X_train, mean, std)\n",
    "# X_test = norma(X_test, mean, std)\n",
    "\n",
    "#clf = Ridge(alpha=my_lambda_opt)\n",
    "#clf.fit(X_train, Y_train)\n",
    "betas_opt = ridge_regression(X_train, Y_train, lam)\n",
    "Y_test_hat = np.dot(X_test, betas_opt)\n",
    "#Y_test_hat = clf.predict(X_test)\n",
    "\n",
    "print('best MSE:', np.mean(np.power(Y_test - Y_test_hat,2)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "S = pd.Series({'MSE_train' : mean_squared_error(Y_train,np.dot(X_train, betas_opt)),\n",
    "                   'MSE_valid' : mean_squared_error(Y_test,np.dot(X_test, betas_opt)),\n",
    "                   'Pred' : np.dot(X_test, betas_opt).reshape(-1),\n",
    "                   'True' : Y_test.reshape(-1)})\n",
    "\n",
    "# settings\n",
    "Title = \"True value vs residual\"\n",
    "x_label =\"True value\"\n",
    "y_label = \"Residual\"\n",
    "savename = \"Ridge-raw-excl0\"\n",
    "\n",
    "plt.plot(S['True'],S['Pred']-S['True'],marker='o', color='dodgerblue',linestyle='none')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel(x_label,size=15)\n",
    "ax.set_ylabel(y_label,size=15)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "ax.set_title(Title,size=15)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"{}.pdf\".format(savename), bbox_inches='tight')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSE_train                                          0.000701733\n",
       "MSE_valid                                          0.000402138\n",
       "Pred         [0.0243597413421, 0.0184859864039, 0.008361346...\n",
       "True         [0.06, 0.05, -0.01, 0.04, 0.03, 0.01, 0.02, 0....\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "best MSE: 0.133547756038\n",
      "best lambda: 11.1692500051 \n",
      "\n",
      "fold: 2\n",
      "best MSE: 0.0221533451849\n",
      "best lambda: 353.813489813 \n",
      "\n",
      "fold: 3\n",
      "best MSE: 0.015181649293\n",
      "best lambda: 0.875933700488 \n",
      "\n",
      "fold: 4\n",
      "best MSE: 0.014060140248\n",
      "best lambda: 10827.2274109 \n",
      "\n",
      "fold: 5\n",
      "best MSE: 0.0135557890361\n",
      "best lambda: 100000.0 \n",
      "\n",
      "the opt. lambda is: 22238.6172169\n",
      "best MSE: 0.000233060507628\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "dataset = MCVDDataset(csv_file='dataset.csv')\n",
    "dataset.mcvd_data = dataset.mcvd_data.drop('Unnamed: 0',axis=1)\n",
    "dataset.mcvd_data.iloc[:,6:306] = min_max_scaler.fit_transform(dataset.mcvd_data.iloc[:,6:306].T).T\n",
    "dataset.mcvd_data['starttime'] = pd.to_datetime(dataset.mcvd_data['starttime'])\n",
    "\n",
    "randomseed=23\n",
    "k_fold=5\n",
    "split = 0.20\n",
    "train_idx, test_idx = get_valid_train_split(dataset.mcvd_data,split=split,randomseed=randomseed,silent=True)\n",
    "\n",
    "X_train = np.empty([0,344])\n",
    "Y_train = np.empty([0,1])\n",
    "for idx in train_idx:\n",
    "    X_train = np.append(X_train,dataset.__getitem__(idx)['data'].reshape(1,344),axis=0)\n",
    "    Y_train = np.append(Y_train,dataset.__getitem__(idx)['target'].reshape(1,1),axis=0)\n",
    "    \n",
    "    \n",
    "X_test = np.empty([0,344])\n",
    "Y_test = np.empty([0,1])\n",
    "for idx in test_idx:\n",
    "    X_test = np.append(X_test,dataset.__getitem__(idx)['data'].reshape(1,344),axis=0)\n",
    "    Y_test = np.append(Y_test,dataset.__getitem__(idx)['target'].reshape(1,1),axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "df = dataset.mcvd_data.loc[train_idx].reset_index()\n",
    "idxcv1 = df.loc[df['adjustment'] !=0].index.values\n",
    "\n",
    "idxcv2 = df.loc[df['adjustment'] ==0].index.values\n",
    "\n",
    "cv1 = np.array_split(idxcv1, k_fold)\n",
    "cv2 = np.array_split(idxcv2, k_fold)\n",
    "\n",
    "\n",
    "folds = [np.concatenate((cv1[i], cv2[i])) for i in range(k_fold)]\n",
    "\n",
    "# CV\n",
    "idx_cv = np.random.choice(np.arange(X_train.shape[0]), replace=False, size=int(X_train.shape[0] * split))\n",
    "\n",
    "\n",
    "# hyperparamters\n",
    "n_steps = 2000\n",
    "my_lambda = np.logspace(start=-5, stop=5, num=n_steps)\n",
    "dev_loss = np.empty((k_fold, n_steps))\n",
    "\n",
    "\n",
    "for i, idx_dev_cv in enumerate(folds):\n",
    "    print(\"fold: \" + str(i+1))\n",
    "\n",
    "    \n",
    "    idx_train_cv = np.array([i for i in np.arange(X_train.shape[0]) if not i in idx_dev_cv])\n",
    "    # create train and dev data\n",
    "    \n",
    "    X_train_cv = X_train[idx_train_cv,]\n",
    "    Y_train_cv = Y_train[idx_train_cv]\n",
    "    \n",
    "    X_dev_cv = X_train[idx_dev_cv,]\n",
    "    Y_dev_cv = Y_train[idx_dev_cv]\n",
    "\n",
    "    # find properties...\n",
    "    mean = np.mean(X_train_cv, axis=0)\n",
    "    std = np.std(X_train_cv, axis=0)\n",
    "    # min = np.min(X_train_cv, axis=0)\n",
    "    # max = np.max(X_train_cv, axis=0)\n",
    "    \n",
    "    \n",
    "    # pre-process\n",
    "    #X_train_cv = zscale(X_train_cv, mean, std)\n",
    "    #X_dev_cv = zscale(X_dev_cv, mean, std)\n",
    "    # X_train_cv = norma(X_train_cv, mean, std)\n",
    "    # X_dev_cv = norma(X_dev_cv, mean, std)\n",
    "    \n",
    "    \n",
    "    for j, lam in enumerate(my_lambda):\n",
    "        # fit \n",
    "        # clf = Ridge(alpha=lam, fit_intercept=False, normalize=True)\n",
    "        # clf.fit(X_train_cv, Y_train_cv)\n",
    "        betas = ridge_regression(X_train_cv, Y_train_cv, lam)\n",
    "        \n",
    "        # predict and get loss\n",
    "        # Y_dev_cv_hat = clf.predict(X_dev_cv)\n",
    "        Y_dev_cv_hat = np.dot(X_dev_cv, betas)\n",
    "        dev_loss[i,j] = np.sum(np.power(Y_dev_cv - Y_dev_cv_hat,2))\n",
    "        \n",
    "        \n",
    "    print('best MSE:', np.min(dev_loss[i,]))\n",
    "    print('best lambda:', my_lambda[np.argmin(dev_loss[i,])], '\\n')\n",
    "\n",
    "\n",
    "# # One std. error rule\n",
    "# std_means = np.std(dev_loss, axis=0) / np.sqrt(k_fold)\n",
    "# mse_means = np.mean(dev_loss, axis=0)\n",
    "# best_idx_std_means = np.argmin(std_means)\n",
    "# best_idx_std_means = np.max(np.where(std_means[best_idx_std_means] + std_means[best_idx_std_means] > std_means)[0])\n",
    "# my_lambda_opt = my_lambda[best_idx_std_means]\n",
    "\n",
    "# # GLOBAL\n",
    "# my_lambda_opt = my_lambda[np.argmin(np.mean(dev_loss, axis=0))]\n",
    "\n",
    "# LOCAL\n",
    "my_lambda_opt = np.mean([my_lambda[np.argmin(dev_loss[i,])] for i in range(dev_loss.shape[0])])\n",
    "print('the opt. lambda is: ' + str(my_lambda_opt))\n",
    "\n",
    "# find properties...\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "# min = np.min(X_train_cv, axis=0)\n",
    "# max = np.max(X_train_cv, axis=0)\n",
    "\n",
    "# pre-process\n",
    "#X_train = zscale(X_train, mean, std)\n",
    "#X_test = zscale(X_test, mean, std)\n",
    "# X_train = norma(X_train, mean, std)\n",
    "# X_test = norma(X_test, mean, std)\n",
    "\n",
    "#clf = Ridge(alpha=my_lambda_opt)\n",
    "#clf.fit(X_train, Y_train)\n",
    "betas_opt = ridge_regression(X_train, Y_train, lam)\n",
    "Y_test_hat = np.dot(X_test, betas_opt)\n",
    "#Y_test_hat = clf.predict(X_test)\n",
    "\n",
    "print('best MSE:', np.mean(np.power(Y_test - Y_test_hat,2)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "S = pd.Series({'MSE_train' : mean_squared_error(Y_train,np.dot(X_train, betas_opt)),\n",
    "                   'MSE_valid' : mean_squared_error(Y_test,np.dot(X_test, betas_opt)),\n",
    "                   'Pred' : np.dot(X_test, betas_opt).reshape(-1),\n",
    "                   'True' : Y_test.reshape(-1)})\n",
    "\n",
    "# settings\n",
    "Title = \"True value vs residual\"\n",
    "x_label =\"True value\"\n",
    "y_label = \"Residual\"\n",
    "savename = \"Ridge-norm\"\n",
    "\n",
    "plt.plot(S['True'],S['Pred']-S['True'],marker='o', color='dodgerblue',linestyle='none')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel(x_label,size=15)\n",
    "ax.set_ylabel(y_label,size=15)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "ax.set_title(Title,size=15)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"{}.pdf\".format(savename), bbox_inches='tight')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSE_train                                          0.000374857\n",
       "MSE_valid                                          0.000233061\n",
       "Pred         [0.000496754995387, 0.000499962101037, 0.00049...\n",
       "True         [0.0, 0.0, 0.06, 0.05, 0.0, 0.0, 0.0, -0.01, 0...\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized excluding 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "best MSE: 0.133204646864\n",
      "best lambda: 3.65410809742 \n",
      "\n",
      "fold: 2\n",
      "best MSE: 0.0220835961156\n",
      "best lambda: 187.774588281 \n",
      "\n",
      "fold: 3\n",
      "best MSE: 0.0143247820022\n",
      "best lambda: 0.42886060911 \n",
      "\n",
      "fold: 4\n",
      "best MSE: 0.0138444669485\n",
      "best lambda: 5424.5933046 \n",
      "\n",
      "fold: 5\n",
      "best MSE: 0.0135430934889\n",
      "best lambda: 100000.0 \n",
      "\n",
      "the opt. lambda is: 21123.2901723\n",
      "best MSE: 0.00048180168611\n"
     ]
    }
   ],
   "source": [
    "dataset = MCVDDataset(csv_file='dataset.csv')\n",
    "dataset.mcvd_data = dataset.mcvd_data.drop('Unnamed: 0',axis=1)\n",
    "dataset.mcvd_data.iloc[:,6:306] = min_max_scaler.fit_transform(dataset.mcvd_data.iloc[:,6:306].T).T\n",
    "dataset.mcvd_data['starttime'] = pd.to_datetime(dataset.mcvd_data['starttime'])\n",
    "dataset.mcvd_data = dataset.mcvd_data[dataset.mcvd_data['adjustment'] != 0].reset_index(drop=True)\n",
    "\n",
    "randomseed=23\n",
    "k_fold=5\n",
    "split = 0.20\n",
    "train_idx, test_idx = get_valid_train_split(dataset.mcvd_data,split=split,randomseed=randomseed,silent=True)\n",
    "\n",
    "X_train = np.empty([0,344])\n",
    "Y_train = np.empty([0,1])\n",
    "for idx in train_idx:\n",
    "    X_train = np.append(X_train,dataset.__getitem__(idx)['data'].reshape(1,344),axis=0)\n",
    "    Y_train = np.append(Y_train,dataset.__getitem__(idx)['target'].reshape(1,1),axis=0)\n",
    "    \n",
    "    \n",
    "X_test = np.empty([0,344])\n",
    "Y_test = np.empty([0,1])\n",
    "for idx in test_idx:\n",
    "    X_test = np.append(X_test,dataset.__getitem__(idx)['data'].reshape(1,344),axis=0)\n",
    "    Y_test = np.append(Y_test,dataset.__getitem__(idx)['target'].reshape(1,1),axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "df = dataset.mcvd_data.loc[train_idx].reset_index()\n",
    "idxcv1 = df.loc[df['adjustment'] !=0].index.values\n",
    "\n",
    "idxcv2 = df.loc[df['adjustment'] ==0].index.values\n",
    "\n",
    "cv1 = np.array_split(idxcv1, k_fold)\n",
    "cv2 = np.array_split(idxcv2, k_fold)\n",
    "\n",
    "\n",
    "folds = [np.concatenate((cv1[i], cv2[i])) for i in range(k_fold)]\n",
    "\n",
    "# CV\n",
    "idx_cv = np.random.choice(np.arange(X_train.shape[0]), replace=False, size=int(X_train.shape[0] * split))\n",
    "\n",
    "\n",
    "# hyperparamters\n",
    "n_steps = 2000\n",
    "my_lambda = np.logspace(start=-5, stop=5, num=n_steps)\n",
    "dev_loss = np.empty((k_fold, n_steps))\n",
    "\n",
    "\n",
    "for i, idx_dev_cv in enumerate(folds):\n",
    "    print(\"fold: \" + str(i+1))\n",
    "\n",
    "    \n",
    "    idx_train_cv = np.array([i for i in np.arange(X_train.shape[0]) if not i in idx_dev_cv])\n",
    "    # create train and dev data\n",
    "    \n",
    "    X_train_cv = X_train[idx_train_cv,]\n",
    "    Y_train_cv = Y_train[idx_train_cv]\n",
    "    \n",
    "    X_dev_cv = X_train[idx_dev_cv,]\n",
    "    Y_dev_cv = Y_train[idx_dev_cv]\n",
    "\n",
    "    # find properties...\n",
    "    mean = np.mean(X_train_cv, axis=0)\n",
    "    std = np.std(X_train_cv, axis=0)\n",
    "    # min = np.min(X_train_cv, axis=0)\n",
    "    # max = np.max(X_train_cv, axis=0)\n",
    "    \n",
    "    \n",
    "    # pre-process\n",
    "    #X_train_cv = zscale(X_train_cv, mean, std)\n",
    "    #X_dev_cv = zscale(X_dev_cv, mean, std)\n",
    "    # X_train_cv = norma(X_train_cv, mean, std)\n",
    "    # X_dev_cv = norma(X_dev_cv, mean, std)\n",
    "    \n",
    "    \n",
    "    for j, lam in enumerate(my_lambda):\n",
    "        # fit \n",
    "        # clf = Ridge(alpha=lam, fit_intercept=False, normalize=True)\n",
    "        # clf.fit(X_train_cv, Y_train_cv)\n",
    "        betas = ridge_regression(X_train_cv, Y_train_cv, lam)\n",
    "        \n",
    "        # predict and get loss\n",
    "        # Y_dev_cv_hat = clf.predict(X_dev_cv)\n",
    "        Y_dev_cv_hat = np.dot(X_dev_cv, betas)\n",
    "        dev_loss[i,j] = np.sum(np.power(Y_dev_cv - Y_dev_cv_hat,2))\n",
    "        \n",
    "        \n",
    "    print('best MSE:', np.min(dev_loss[i,]))\n",
    "    print('best lambda:', my_lambda[np.argmin(dev_loss[i,])], '\\n')\n",
    "\n",
    "\n",
    "# # One std. error rule\n",
    "# std_means = np.std(dev_loss, axis=0) / np.sqrt(k_fold)\n",
    "# mse_means = np.mean(dev_loss, axis=0)\n",
    "# best_idx_std_means = np.argmin(std_means)\n",
    "# best_idx_std_means = np.max(np.where(std_means[best_idx_std_means] + std_means[best_idx_std_means] > std_means)[0])\n",
    "# my_lambda_opt = my_lambda[best_idx_std_means]\n",
    "\n",
    "# # GLOBAL\n",
    "# my_lambda_opt = my_lambda[np.argmin(np.mean(dev_loss, axis=0))]\n",
    "\n",
    "# LOCAL\n",
    "my_lambda_opt = np.mean([my_lambda[np.argmin(dev_loss[i,])] for i in range(dev_loss.shape[0])])\n",
    "print('the opt. lambda is: ' + str(my_lambda_opt))\n",
    "\n",
    "# find properties...\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "# min = np.min(X_train_cv, axis=0)\n",
    "# max = np.max(X_train_cv, axis=0)\n",
    "\n",
    "# pre-process\n",
    "#X_train = zscale(X_train, mean, std)\n",
    "#X_test = zscale(X_test, mean, std)\n",
    "# X_train = norma(X_train, mean, std)\n",
    "# X_test = norma(X_test, mean, std)\n",
    "\n",
    "#clf = Ridge(alpha=my_lambda_opt)\n",
    "#clf.fit(X_train, Y_train)\n",
    "betas_opt = ridge_regression(X_train, Y_train, lam)\n",
    "Y_test_hat = np.dot(X_test, betas_opt)\n",
    "#Y_test_hat = clf.predict(X_test)\n",
    "\n",
    "print('best MSE:', np.mean(np.power(Y_test - Y_test_hat,2)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "S = pd.Series({'MSE_train' : mean_squared_error(Y_train,np.dot(X_train, betas_opt)),\n",
    "                   'MSE_valid' : mean_squared_error(Y_test,np.dot(X_test, betas_opt)),\n",
    "                   'Pred' : np.dot(X_test, betas_opt).reshape(-1),\n",
    "                   'True' : Y_test.reshape(-1)})\n",
    "\n",
    "# settings\n",
    "Title = \"True value vs residual\"\n",
    "x_label =\"True value\"\n",
    "y_label = \"Residual\"\n",
    "savename = \"Ridge-norm-excl0\"\n",
    "\n",
    "plt.plot(S['True'],S['Pred']-S['True'],marker='o', color='dodgerblue',linestyle='none')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel(x_label,size=15)\n",
    "ax.set_ylabel(y_label,size=15)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "ax.set_title(Title,size=15)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"{}.pdf\".format(savename), bbox_inches='tight')#\n",
    "#ax.ticklabel_format(style='sci', axis='x', scilimits=(0,0),size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSE_train                                             0.000749\n",
       "MSE_valid                                          0.000481802\n",
       "Pred         [0.000665413014304, 0.000666494694588, 0.00067...\n",
       "True         [0.06, 0.05, -0.01, 0.04, 0.03, 0.01, 0.02, 0....\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
